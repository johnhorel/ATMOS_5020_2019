{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Storage and Manipulation with Pandas\n",
    "We've taken a look at using Numpy arrays for data storage, now lets turn to another solution for organizing and manipulating data. This package is called Pandas and relies on \"dataframe\" objects which allow for more efficient labeling, indexing, and operations on large datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the package\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pandas to create \"series\" objects which function much like arrays in numpy. Try running the following block of code to see how creating a series object works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([-2,-1,0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This series is stored with appropriate indecies, and we can extract both the values and indecies by running either data.values or data.indicies. Indexing into the series is done in the same way as numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data,\"\\n...........\")\n",
    "print(data.values,\"\\n...........\")\n",
    "print(data.index,\"\\n...........\")\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "Dataframes provide a nice way to store data with labels. Often when working with large datasets containing many different variables, it becomes helpful to referenece columns or rows by a label instead of a numbered index. There are many ways to build a pandas dataframe -- let's examine a couple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Direct creaton of a dataframe with data\n",
    "df1 = pd.DataFrame([2,4,6,8]) #indecies are automatically assigned (0,1,2,...)\n",
    "df2 = pd.DataFrame([2,4,6,8],['human','dog','insect','spider']) #indecies are specified by second argument pd.DataFrame(data,indecies)\n",
    "df3 = pd.DataFrame([2,4,6,8],['human','dog','insect','spider'],columns = ['Legs']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation from numpy arrays\n",
    "import numpy as np\n",
    "x = np.arange(-5,5,1)\n",
    "y = np.arange(10,101,10)\n",
    "z = np.linspace(0,1,10)\n",
    "matrix = [x,y,z]\n",
    "\n",
    "df4 = pd.DataFrame(matrix).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Column Names\n",
    "cols = ['Col1','Col2','Col3']\n",
    "df4.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index manipulation\n",
    "#df4.set_index('Col1')  #inplace=True\n",
    "#df4.reset_index() #Drop=False, inplace = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing part of the data\n",
    "#df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a column\n",
    "c4 = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "df4['Col4'] = c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing into dataframes\n",
    "df4['Col1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling in data from other sources\n",
    "We can also use pandas to pull data from other sources. There are a plethora of ways data can be stored - SQL tables, txt, csv, pkl, etc. Finding the right application given a data source is as simple as a google search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, lets add some CSV data. Navigate to the github page and download \"eddy.csv\" and save to a location on your computer where you know where it lives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/tluBCEZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgur.com/ElrlfMk.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv data to dataframe\n",
    "source = pd.read_csv('source_data.csv')\n",
    "tower = pd.read_csv('tower_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #import the package\n",
    "fig,ax = plt.subplots() #setup the figure\n",
    "ax.plot(source['Local_DT'],source['LI_CO2']) #plot the data\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10)) #set the number of x axis ticks\n",
    "plt.gcf().autofmt_xdate() #get a nice date format for the x axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots() #setup the figure\n",
    "ax.plot(tower['Local_DT'],tower['PIC_CO2']) #plot the data\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))  #set the number of x axis ticks\n",
    "plt.gcf().autofmt_xdate() #get a nice date format for the x axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip the data to a shorter time window\n",
    "DT1 = '2018-09-05 18:00:00'\n",
    "DT2 = '2018-09-05 19:30:00'\n",
    "source_clipped = source.loc[(source['Local_DT']>=DT1)&(source['Local_DT']<=DT2)].reset_index(drop=True)\n",
    "tower_clipped = tower.loc[(tower['Local_DT']>=DT1)&(tower['Local_DT']<=DT2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as grd\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "gs = grd.GridSpec(2,1)\n",
    "ax = fig.add_subplot(gs[0])\n",
    "ax.plot(source_clipped['EPOCH_TIME'],source_clipped['LI_CO2'],color='blue')\n",
    "ax = fig.add_subplot(gs[1],sharex=ax)\n",
    "ax.plot(tower_clipped['EPOCH_TIME'],tower_clipped['PIC_CO2'],color='red')\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "We can also merge dataframes together by index - in this case lets use the EPOCH_TIME. Sometimes some errors arise and we need to deal with them in unique ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set epoch time as index concatenation\n",
    "tower.index = tower['EPOCH_TIME']\n",
    "del(tower['EPOCH_TIME'])\n",
    "source.index = source['EPOCH_TIME']\n",
    "del(source['EPOCH_TIME'])\n",
    "\n",
    "#Ensure there are no duplicate epochs - I was getting an error when trying to concatenate for some reason\n",
    "source = source[~source.index.duplicated(keep='first')]\n",
    "tower = tower[~tower.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([tower,source],axis=1).dropna().drop('Local_DT',axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running functions on DataFrames\n",
    "Often we will want to run functions using data within the dataframe to create a new column, much like what most people are familiar with doing in excel. Lets take a look at how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_speed(row):\n",
    "    return np.sqrt(row['ANEM_X']**2+row['ANEM_Y']**2)\n",
    "\n",
    "\n",
    "def direction(row):\n",
    "    d = np.arctan2(row['ANEM_Y'],row['ANEM_X'])*180.0/np.pi\n",
    "    if d < 0:\n",
    "        return 360.0 + d\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['speed'] = full_df.apply(lambda row: xy_speed(row),axis=1)\n",
    "full_df['direction'] = full_df.apply(lambda row: direction(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
